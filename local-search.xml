<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Differential Privacy - Composition Theorems</title>
    <link href="/2020/10/17/Composition%20Theorems%20for%20Differential%20Privacy/"/>
    <url>/2020/10/17/Composition%20Theorems%20for%20Differential%20Privacy/</url>
    
    <content type="html"><![CDATA[<p>This post mainly introduce the composition theorems of differential privacy. It is proposed by Cynthia Dwork in <strong>《Boosting and Differential Privacy》</strong>. It shows that, for achieving ($\epsilon$, $\delta$) differential privacy of $k$-fold composition, the privacy parameter $\epsilon$ degrades as $k \epsilon^2+\sqrt{k}\epsilon$ rather than linearly as $k\epsilon$.</p><a id="more"></a><p>With multiple differentially private mechanisms, we can put them together to construct more complicted private algorithms. But in order to do that, we need to understand how privacy parameters compose.</p><p>Before we begin, we must discuss what exactly we mean by composition. It covers the following two interesting scenarios:</p><ol><li>Repeated use of differentially private algorithms on the same database. This allows both the repeated use of the same mechanism multiple times, as well as the modular construction of differentially private algorithms from basic private building blocks.</li><li>Repeated use of differentially private algorithms on <em>different</em> databases that may nevertheless contain information relating to the same individual. This allows us to reason about the cumulative privacy loss of a single individual whose data might be spread across multiple datasets, each of which may be used indenpendently in a differentially private way.</li></ol><p>Towards this end, we consider the following composition experiment, which takes as input an arbitrary adaptive algorithm $\mathcal{A}$ which we view as the “adversary” trying to break the privacy of some family of database access mechanisms $\mathcal{M}$ (e.g.  the set of all $\epsilon$-defferentially private mechanisms), as well as a parameter $b$ which can take values either 0 or 1.</p><pre><code class="hljs pdflatex">\begin&#123;algorithm&#125;[H]\caption&#123;$k$-fold Adaptive Composition Experiment b for an adversary $mathcal&#123;A&#125;$ and a family of database mechanisms $\mathcal&#123;M&#125;$&#125;\Compose($\mathcal&#123;A&#125;, \mathcal&#123;M&#125;,k,b$)\For&#123;$i &#x3D; 1 \to k$&#125;&#123;$\mathcal&#123;A&#125;$ outputs two neighboring databases $D^&#123;i,0&#125;,D^&#123;i,1&#125; \to \mathit&#123;N&#125;^&#123;|x|&#125; and a mechanism $mathcal&#123;M&#125;_i \to \mathcal&#123;M&#125;$$\mathcal&#123;A&#125;$ receives $y_i&#x3D;\mathcal&#123;M&#125;_i(D^&#123;i,b&#125;)$&#125;\end&#123;algorithm&#125;</code></pre><p>With respec</p>]]></content>
    
    
    
    <tags>
      
      <tag>Differential Pricacy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>How Not to Prove Your Election Outcome</title>
    <link href="/2020/07/10/How%20Not%20to%20Prove%20Your%20Election%20Outcome/"/>
    <url>/2020/07/10/How%20Not%20to%20Prove%20Your%20Election%20Outcome/</url>
    
    <content type="html"><![CDATA[<p><strong>Abstract</strong></p><p>The Scytl/SwissPost e-voting solution was intended to provide complete veriﬁability for Swiss government elections. We show failures in both individual veriﬁability and universal veriﬁability (as deﬁned in Swiss Federal Ordinance 161.116), based on mistaken implementations of cryptographic components. These failures allow for the construction of “proofs” of an accurate election outcome that pass veriﬁcation though the votes have been manipulated. Using sophisticated cryptographic protocols without a proper consideration of what properties they offer, and under which conditions, can introduce opportunities for undetectable fraud even though the system appears to allow veriﬁcation of the outcome.</p><a id="more"></a><p>分析了投票选举系统存在的安全性问题</p>]]></content>
    
    
    
    <tags>
      
      <tag>IEEE S&amp;P 2020</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GBDT</title>
    <link href="/2020/07/01/GBDT/"/>
    <url>/2020/07/01/GBDT/</url>
    
    <content type="html"><![CDATA[<p>介绍<strong>GBDT</strong>，并记录<strong>XGBoost</strong>理论推导。</p><a id="more"></a><p>GBDT(Gradient Boost Decision Tree)，即利用Gradient Boost的学习策略来训练决策树。Boost的策略我们已经有所了解，但Gradient又是如何体现的呢？</p><p>整个算法最后的训练得到的是$k$个简单的决策树：$T_1,T_2,…,T_k$，而模型的输出，则是样本在各个决策树上的结果之和：</p><script type="math/tex; mode=display">\hat{y}=\sum_{i=1}^{k}f_{i}(x),f_k\subset\Gamma</script><p>其中，$ f_k$表示样本到树输出的映射。</p><h3 id="XGBoost理论推导"><a href="#XGBoost理论推导" class="headerlink" title="XGBoost理论推导"></a>XGBoost理论推导</h3><p>已知GBDT可以用以下公式表示:</p><p>$\hat{y}=\sum_{i=1}^{k}f_{i}(x),f_k\subset\Gamma$</p><p>优化目标为：</p><p>$Obj=\sum\limits_{i=1}^{n}l(y_i, \hat{y_i})+\sum\limits_{i=1}^{K}\Omega(f_i)$</p><p>那么我们的目标则为训练一组数，令$Obj$达到最小</p><h4 id="追加训练法（Additive-Training，Boost）"><a href="#追加训练法（Additive-Training，Boost）" class="headerlink" title="追加训练法（Additive Training，Boost）"></a>追加训练法（Additive Training，Boost）</h4><p>其核心思想为，在保持$T_1, T_2,…,T_{k-1}$不变的情况下，训练$T_k$，其表示方法如下：</p><p>$(1)\;\hat{y}^{(0)}=0$，算法初始化</p><p>$(2)\;\hat{y}^{(1)}=f_1(x)$，训练第一棵树</p><p>$(3)\;\hat{y}^{(2)}=f_1(x)+f_2(x)=\hat{y}^{(1)}+f_2(x)$，训练第二棵树，同时保持第一棵树保持不变</p><p>$(4)\;\hat{y}^{(t)} = \sum\limits_{i=1}^{t-1}f_i(x)+f_t(x)=\hat{y}^{(t-1)}+f_t(x)$，训练第$t$棵树，同时保持前$t-1$棵保持不变</p><p>假设此时对第$t$棵树保持不变，则损失函数为：</p><script type="math/tex; mode=display">\begin{aligned}Obj^{(t)}&=\sum\limits_{i=1}^{n}l(y_i,\hat{y_i}^{(t)})+\sum\limits_{i=1}^{t}\Omega(f_i)\\&=\sum\limits_{i=1}^{n}l(y_i,\hat{y_i}^{(t-1)}+f_t(x_i))+\Omega(f_t)+constant\end{aligned}</script><p>将$\hat{y_i}^{(t-1)}$看做变量$x$，$f_t(x_i)$看做$\Delta x$，则利用$Taylor$展开公式，可得到：</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}Obj^{(t)}&=\sum\limits_{i=1}^{n}l(y_i,\hat{y_i}^{(t-1)}+f_t(x_i))+\Omega(f_t)+constant\\&=\sum\limits_{i=1}^{n}[l(y_i,\hat{y_i}^{(t-1)})+g_{i}f_t(x_i)+\frac{1}{2} h_if_t^2(x_i)]+\Omega(f_t)+constant\\&=\sum\limits_{i=1}^{n}[g_{i}f_t(x_i)+\frac{1}{2} h_if_t^2(x_i)]+\Omega(g_t)+constant\end{aligned}\end{equation}</script><p>其中，$\sum\limits_{i=1}^{n}l(y_i,\hat{y_i}^{(t-1)})$为一个常量，因此可以省略，$g_i$和$h_i$分别对应一阶偏导和二阶偏导：</p><script type="math/tex; mode=display">g_i = \frac{\partial l(y_i,\hat{y}^{(t-1)})}{\hat{y}^{(t-1)}}\\h_i = \frac{\partial^{2} l(y_i,\hat{y}^{(t-1)})}{\hat{y}^{(t-1)}}\\</script><p>因为常量$constant$可以省略，因此我们可以优化一个新的目标函数：</p><script type="math/tex; mode=display">Obj^{(t)}=\sum\limits_{i=1}^{n}[g_{i}f_t(x_i)+\frac{1}{2} h_if_t^2(x_i)]+\Omega(g_t)</script><h4 id="复杂度函数-Omega-f-t-的引入"><a href="#复杂度函数-Omega-f-t-的引入" class="headerlink" title="复杂度函数$\Omega(f_t)$的引入"></a>复杂度函数$\Omega(f_t)$的引入</h4><p>假设待训练的第$t$棵树有$T$个叶子节点，叶子节点的输出向量表示为$[w_1,w_2,…,w_T]$，那么$f_t(x)$可以表示为如下形式：</p><script type="math/tex; mode=display">f_t(x)=w_{q(x)},w\in R^T,q(x):R^d\rightarrow \{1,2,...,T\}</script><p>在$XGBoost$中，复杂度函数$\Omega(f_t)$的定义如下：</p><script type="math/tex; mode=display">\Omega(f_t)=\gamma T+\frac{1}{2}\lambda \sum\limits_{j=1}^{T}w_{j}^2</script><p>则目标函数的推导如下：</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}Obj^{(t)}&=\sum\limits_{i=1}^{n}[g_{i}f_t(x_i)+\frac{1}{2} h_if_t^2(x_i)]+\gamma T+\frac{1}{2}\lambda \sum\limits_{j=1}^{T}w_{j}^2\\&=\sum\limits_{i=1}^{n}[g_iw_{q(x_i)}+\frac{1}{2}h_iw_{q(x_i)}^{2}]+\gamma T+\frac{1}{2}\lambda \sum\limits_{j=1}^{T}w_{j}^2\\&=\sum\limits_{j=1}^{T}[(\sum\limits_{i\in I_j}g_i)w_j+\frac{1}{2}\sum\limits_{i\in I_j}h_iw_j^2]+\gamma T+\frac{1}{2}\lambda \sum\limits_{j=1}^{T}w_{j}^2\\&=\sum\limits_{j=1}^{T}[(\sum\limits_{i\in I_j}g_i)w_j+\frac{1}{2}(\sum\limits_{i\in I_j}h_i+\lambda) w_{j}^2]+\gamma T\\\end{aligned}\end{equation}</script><p>定义$G_j=\sum\limits_{i\in I_j}g_i$，$H_j=\sum\limits_{i\in I_j}h_i$，则上式变为：</p><script type="math/tex; mode=display">Obj^{(t)}=\sum\limits_{j=1}^{T}[G_jw_j+\frac{1}{2}(H_j+\lambda) w_{j}^2]+\gamma T\\</script><p>对上式看做T个相互独立的二次函数的累加，则求目标函数最小等价于求每个二次函数的最小。当H_i&gt;0，可求得：</p><script type="math/tex; mode=display">w_j^*=-\frac{G_i}{H_i+\lambda}\\Obj_{min}^{(t)} = -\frac{1}{2}\sum\limits_{j=1}^{T}(\frac{G_j^2}{H_j+\lambda})+\gamma T\\</script><p>举个例子，假设要求解第一棵树$T_1$的结构如下，各个样本按照该树的结构，会被映射到相应的位置，得到每个样本 $x_i$ 对应的$g_i,h_i$，就可以求得到相应的$Obj_{min}^{(1)}$</p><p><img src="GBDT.assets/GBDT.jpg" srcset="/img/loading.gif" alt="GBDT" style="zoom:67%;" /></p><p>$g_i,h_i$为前文定义损失函数$l(y_i,\hat{y}^{(t-1)})$对$\hat{y}^{(t)}$的一阶偏导数和二阶偏导数，则当损失函数定义为平方差损失，则可得到：</p><script type="math/tex; mode=display">g_i = \frac{\partial (y_i-\hat{y}^{(t-1)})^2}{\hat{y}^{(t-1)}}=-2(y_i-\hat{y}^{(t-1)})\\h_i = \frac{\partial^{2} (y_i-\hat{y}^{(t-1)})^2}{\hat{y}^{(t-1)}}=2\\</script><p>所以对于待训练的新树而言，可以根据已经训练好的树预先计算$g_i,h_i$，枚举所有可能的新树的结构，选择目标函数最小的那棵树，同时使用$w_j^*=-\frac{G_i}{H_i+\lambda}$求得该树每个叶子节点的输出值。然而，枚举所有的树是不现实的，因为样本特征值可能是连续的，树的结构可能是无穷的。</p><h4 id="贪心法求解树"><a href="#贪心法求解树" class="headerlink" title="贪心法求解树"></a>贪心法求解树</h4><p>在XGboost中利用贪心法求解树，其算法描述如下：</p><ol><li><p>初始化树，深度为0；</p></li><li><p>对于每个叶子节点，尝试分裂该节点，分裂后的增益为</p><script type="math/tex; mode=display">Gain=\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]-\lambda</script><p>该公式定义了，分裂后左右子树的新增得分减去不分裂时候节点得分，再减去因为新增一个节点增加的复杂度。</p></li></ol><p>那么如何定义最佳分裂点：</p><ul><li>对于每个叶子节点，枚举所有的特征</li><li>对每个特征，把映射到该叶节点的样本按照该特征值排序</li><li>使用线性扫描来决定最佳分裂点 $O(nKd\log n)$，其中$n$为样本数量，$K$为树深度，$d$为特征数量</li><li>在所有枚举的特征中，选择最优的分裂</li></ul><h3 id="总结算法流程"><a href="#总结算法流程" class="headerlink" title="总结算法流程"></a>总结算法流程</h3><ol><li>迭代生成树$T_i$；</li><li>迭代初始，利用训练好的树$T_1,T_2,…,T_{i-1}$，计算$g_i,h_i$；</li><li>以$Obj_{min}^{(t)} = -\frac{1}{2}\sum\limits_{j=1}^{T}(\frac{G_j^2}{H_j+\lambda})+\gamma T $为目标函数，利用贪心算法求得$T_i$；</li><li>新增数后，模型表示为$\hat{y}^{(t)}=\hat{y}^{(t-1)}+f_t(x)$，实践中，可使用$\hat{y}^{(t)}=\hat{y}^{(t-1)}+\epsilon f_t(x)$代替上式，其中$\epsilon$表示步长。</li></ol><p><em>本文参考<a href="https://zhuanlan.zhihu.com/p/30339807" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/30339807</a></em></p><p><em>主要强化记忆，总结知识。</em></p>]]></content>
    
    
    
    <tags>
      
      <tag>决策树，原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The principle of Generative Adversarial Networks</title>
    <link href="/2019/11/08/The%20principle%20of%20Generative%20Adversarial%20Networks/"/>
    <url>/2019/11/08/The%20principle%20of%20Generative%20Adversarial%20Networks/</url>
    
    <content type="html"><![CDATA[<p>最近重温了一遍生成式对抗网络的相关知识, 有了一些新的收获. 理解更深刻了, 思路也更清晰了, 在此记录一下. </p><a id="more"></a><h2 id="Basic-concepts"><a href="#Basic-concepts" class="headerlink" title="Basic concepts"></a>Basic concepts</h2><p>基本概念, 不在过多赘述. 主要就是两个网络之间相互博弈的思想. 但有两点需要思考:</p><ol><li>生成式对抗网络的提出过程不仅仅是简单的想出让两个网络相互博弈的过程. </li><li>生成器和判别器, 为什么最后的结果是生成器达到最强(可以生成以假乱真的图像), 而不是判别器达到最强(可以将真假图像完全区分出来)?</li></ol><h2 id="Basic-idea-of-GAN"><a href="#Basic-idea-of-GAN" class="headerlink" title="Basic idea of GAN"></a>Basic idea of GAN</h2><p>虽然算法最后生成的是与真实图像几乎没有区别的样本, 但实际上生成器得到的是一个分布 $P_{G}(x)$. 我们的目标是想让 $P_{G}(x)$ 尽可能的接近数据的真实分布$P_{data}(x)$.</p><h3 id="KL-divergence"><a href="#KL-divergence" class="headerlink" title="$KL$ divergence"></a>$KL$ divergence</h3><p>在测度论中, 如果我们想要衡量具有同一随机变量的两个独立的概率分布$P(x)$和$Q(x)$的差异, 我们可以用$KL$散度来进行计算:</p><script type="math/tex; mode=display">D_{KL}(P\parallel Q)=\mathit{E}_{x\backsim P(x)}[log\frac{P(x)}{Q(x)}]=\mathit{E}_{x\backsim P(x)}[log P(x)-log Q(x)]</script><p>$KL$散度有很多有用的性质, 最重要的是它是非负的. $KL$散度为0,  当且仅当$P(x)$和$Q(x)$在离散型变量的情况下是相等的, 或在连续型变量的情况下<strong>几乎处处</strong>相等. </p><p>然而, 他有一个缺点那就是非对称的, 这意味着选择$D_{KL}(P\parallel Q)$还是$D_{KL}(Q\parallel P)$影响很大.</p><p>$KL$散度可以由极大似然估计来导出.</p><p>给定一个样本数据的分布$P_{data}(x)$和生成的数据分布$P_{G}(x;\theta)$, 我们希望GAN可以找到一组参数$\theta$, 使分布$P_{data}(x)$和$P_{G}(x;\theta)$之间的距离最短, 从而生成器可以生成十分逼真的图像.</p><p>首先我们从$P_{data}(x)$中抽取m个真实样本$\{x_{1},x_{2},\dots ,x_{m}\}$, 可以计算$P_{G}(x_{i};\theta)$为在由$\theta$生成的分布中, $x_{i}$样本所出现的概率. 因此, 构造似然函数:</p><script type="math/tex; mode=display">L=\prod_{i=1}^{m}P_{G}(x_{i};\theta)</script><p>下面我们最大化似然函数来求得参数$\theta$:</p><script type="math/tex; mode=display">\begin{aligned}\theta^{*}=& \arg \max\limits_{\theta}\prod_{i=1}^{m}P_{G}(x_{i};\theta)=\arg\max\limits_{\theta}\log\prod_{i=1}^{m}P_{G}(x_{i};\theta)\\=&\arg\max\limits_{\theta}\sum_{i=1}^{m}\log\prod_{i=1}^{m}P_{G}(x_{i};\theta)\\\thickapprox&\arg\max\limits_{\theta}\mathit{E}_{x\backsim P_{data}}\log[P_{G}(x_{i};\theta)]\\ =&\arg\max\limits_{\theta}\int_{x}P_{data}(x)\log P_{G}(x;\theta)dx-\int_{x}P_{data}(x)\log P_{data}(x)dx\\=&\arg\min\limits_{\theta}\int_{x}P_{data}(x)[\log P_{data}(x)-\log P_{G}(x;\theta)]dx\\=&\arg\min\limits_{\theta}KL(P_{data}(x)\parallel P_{G}(x))\end{aligned}</script><p>从上式中可以看出, 如果想要找到最优的参数$\theta$, 我们需要找到$P_{data}(x)$与$ P_{G}(x)$之间的$KL$散度. 但在实际操作中, 这是做不到的. 因为我们即使是真实的分布$ P_{data}(x)$也写不出来,跟不用说$ P_{G}(x)$.</p><h3 id="The-advantage-of-GAN"><a href="#The-advantage-of-GAN" class="headerlink" title="The advantage of GAN"></a>The advantage of GAN</h3><p>既然我们求不出$P_{data}(x)$与$ P_{G}(x)$之间的$KL$散度, GAN就想出了一个办法来替代这两个分布之间的差异, 那就是引入判别器$Discriminator$. 利用机器学习的思想, 判别器可以一步步的增强, 以更好的对两个分布之中的样本进行区分.</p><p>而要想得到一个比较好生成器$G$和判别器$D$, 我们需要对下面这一式子进行优化:</p><script type="math/tex; mode=display">G^{*},D^{*}=\min\limits_{\theta}\max\limits_{\theta}V(G,D)</script><p>首先我们需要定义一个判别器$D$以判别样本是不是从$P_{data}$分布中取出来, 因此有:</p><script type="math/tex; mode=display">\mathit{E}_{x\sim p_{data}(x)}\log(D(x))</script><p>最大化这一项相当于令判别器$D$在$x\sim P_{data}(x)$时可以准确预测出$D(x)=1$.</p><p>另一项是企图骗过判别器的生成器$G$. 根据<strong>负类</strong>的对数损失函数构建:</p><script type="math/tex; mode=display">\mathit{E}_{z\sim p(z)}\log(1-D(G(z)))</script><p>最大化这一项, 需要$D(G(x))$尽可能的等于$0$, 因此判别器$D$可以生成的假图像区分出来. 而最小化这一项, $G$就可以骗过判别器达到以假乱真.</p><p>结合以上两个概念, 我们可以定义价值函数:</p><script type="math/tex; mode=display">V(G,D):=\mathit{E}_{x\sim p_{data}(x)}\log(D(x))+\mathit{E}_{z\sim p(z)}\log(1-D(G(z)))</script><p>在实际应用中, 我们可以先初始化一个生成器$G$, 找到在此生成器下最好的判别器$D_{G}^{*}$:</p><script type="math/tex; mode=display">D_{G}^{*}=\arg\max V(G,D)</script><p>然后固定$D$, 并最小化$V(G,D)$以得到最优的$G$:</p><script type="math/tex; mode=display">G^{*}=\arg\min V(G,D_{G}^{*})</script><h3 id="Theoretical-Analysis"><a href="#Theoretical-Analysis" class="headerlink" title="Theoretical Analysis"></a>Theoretical Analysis</h3><p>以下, 我们从理论证明, 可以得到最优的判别器和生成器.</p><h4 id="Finding-the-Best-Discriminator"><a href="#Finding-the-Best-Discriminator" class="headerlink" title="Finding the Best Discriminator"></a><strong>Finding the Best Discriminator</strong></h4><p>首先,我们先假设已知:</p><script type="math/tex; mode=display">\mathit{E}_{z\sim P(z)}\log(1-D(G(z)))=\mathit{E}_{x\sim p_{G}(x)}\log(1-D(x)</script><p>那么:</p><script type="math/tex; mode=display">V(G,D):=\mathit{E}_{x\sim p_{data}(x)}\log(D(x))+\mathit{E}_{x\sim p_{G}(x)}\log(1-D(x)</script><p>将价值函数展开为积分形式:</p><script type="math/tex; mode=display">V(G,D) =\int_{x }p_{data}(x)\log D(x)-p_{g}(x)\log (1-D(x))dx</script><p>如果我们想要令$V(G,D)$达到做大, 则只需要上他的积分函数达到最大. 即, 找到最优的$D(x)$, 令 $p_{data}(x)\log D(x)-p_{g}(x)\log (1-D(x))$ 达到最大. </p><p>将$D(x)$看做变量, 利用求导求极值的放法,可以求得当:</p><script type="math/tex; mode=display">D^{*}(x)=\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}</script><p> 时, $V(G,D)$最大. 且此极大值是唯一的.</p><p>在实际计算中, $D(x)$是不可计算的, 因为我们并不知道先验的$P_{data}(x)$, 但在数学上证明了了他的存在. 并且这可以帮我们证明最优$G$也是存在的.</p><h4 id="Finding-the-Best-Generator"><a href="#Finding-the-Best-Generator" class="headerlink" title="Finding the Best Generator"></a><strong>Finding the Best Generator</strong></h4><p>GAN的目标是令$P_{G}(x)=P_{data}(x)$, 当我们将其代入最优$D(x)$的表达式中, 可以得到</p><script type="math/tex; mode=display">D_{G}^{*}=\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}=\frac{1}{2}</script><p>即判别样本来自$P_{data}(x)$和$P_{G}(x)$的概率都为$\frac{1}{2}$, 也就意味这判别器已经完全分不清真假图像了.(前面思考2的原因)</p><p>基于这一观点, Ian Goodfellow 证明了$G$就是极大极小博弈的解. 以下我们对其进行证明.</p><p>首先我们反向证明, 即已知$P_{G}(x)=P_{data}(x)$, 来找$C(G)=\max V(G,D)$的全局最小点.此时:</p><script type="math/tex; mode=display">\begin{aligned}V(G,D_{G}^*) =&\int_{x }p_{data}(x)\log \frac{1}{2}-p_{g}(x)\log (1-\frac{1}{2})dx\\=&-\log2\int_{x}P_{G}(x)dx-\log2\int_{x}P_{data}(x)dx\\=&-2\log2\\=&-\log4\end{aligned}</script><p>由于只有当$P_{G}(x)=P_{data}(x)$时该值才会出现, 因此接下来我们从正向证明这个值就是最小值, 也就是满足当且仅当的条件.</p><p>放弃$P_{G}(x)=P_{data}(x)$的假设,对任意一个$G$, 我们将最优$D^{*}(x)$代入$C(G)=\max V(G,D)$中:</p><script type="math/tex; mode=display">\begin{aligned}C(G)=&\int_{x}p_{data}(x)\log\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\\+&p_{G}(x)\log\frac{P_{G}(x)}{P_{data}(x)+P_{G}(x)}dx\end{aligned}</script><p>因为已知$-\log4$为全局最小值, 因此我们希望构造某个值使方程中出现$-\log2$.</p><script type="math/tex; mode=display">\begin{aligned}C(G)=&\int_{x}(\log2-\log2)p_{data}(x)+p_{data}(x)\log\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\\+&(\log2-\log2)p_{G}(x)+p_{G}(x)\log\frac{P_{G}(x)}{P_{data}(x)+P_{G}(x)}dx\end{aligned}</script><p>经过简化后, 可以得到:</p><script type="math/tex; mode=display">\begin{aligned}C(G)=&-\log2\int_{x}(p_{data}(x)+p_{G}(x))dx\\+&\int_{x}p_{data}(x)(\log2+\log\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)})\\+&p_{G}(x)(\log2+\log\frac{P_{G}(x)}{P_{data}(x)+P_{G}(x)})dx\end{aligned}</script><p>再经过化简可以得到:</p><script type="math/tex; mode=display">\begin{aligned}C(G)=&-\log4+\int_{x}p_{data}(x)\log\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}\\+&p_{G}(x)\log\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx\end{aligned}</script><p>根据前面$KL$散度的定义, 我们可以发现:</p><script type="math/tex; mode=display">\begin{aligned}C(G)=-\log4+KL(p_{data}\parallel\frac{p_{data}+p_{G}}{2})+KL(p_{data}\parallel\frac{p_{data}+p_{G}}{2})\end{aligned}</script><p>$KL$散度是非负的, 因此我们可以得出$-\log4$就是$C(G)$的全局最小值. 接下来即说明$P_{G}(x)=P_{data}(x)$为唯一的条件. </p><p>引入$JS$散度, $JS(P \parallel Q)=\frac{1}{2}KL(P\parallel M)+\frac{1}{2}KL(P\parallel M)$, 其中$M=\frac{1}{2}(P+Q)$. 因此</p><script type="math/tex; mode=display">C(G)=-\log4+2\cdot JS(P_{data} \parallel P_{G})</script><p>$JS$散度的取值为$0$到$\log2$,.若两个分布完全没有交集,那么$JS$散度取最大值$\log2$; 若另个分布完全一样, 那么$JS$散度取值为$0$. 因此只有当$P_{G}(x)=P_{data}(x)$时, $C(G)$取得最小值$-\log4$.</p><p>由此, 最优生成器和判别器的存在性和唯一性得以证明.</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>生成式对抗网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>InfoGAN 论文</title>
    <link href="/2019/07/25/InfoGAN/"/>
    <url>/2019/07/25/InfoGAN/</url>
    
    <content type="html"><![CDATA[<p>在看完上篇论文后，顺便看了一下<a href="https://arxiv.org/pdf/1606.03657.pdf" target="_blank" rel="noopener"><strong>InfoGAN</strong></a>的原论文。</p><a id="more"></a><p>在<strong>BicycleGAN</strong>中，用到了<a href="https://arxiv.org/pdf/1606.03657.pdf" target="_blank" rel="noopener"><strong>InfoGAN</strong></a>的相关知识，因此又补了一下这篇论文。</p><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>在传统的GANs中，生成器学习到的图像特征比如在人脸图像中，人像是否戴眼镜、发人的色这些特征，都是混合在一起的。在特征空间中，你很难将这些它们分解开来。本文试图利用无监督学习的方法，将这些特征空间进行分解，使其具有更强的解释性。</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>在理想情况下，比如在MNIST手写数据集中，生成器可以自动选择分配随机变量来表示数字标识1-9，并且有两个额外的连续变量来表示数字的理想角度和笔画的粗细。而如果我们我们可以用无监督学习的方法来恢复这些概念，就会非常有用。</p><p>作者首先提出将输入的噪声分为两个部分：$(1)z$，不可压缩的噪声和$(2)c$，潜在编码(latent code)。其中潜在编码是针对数据分布的结构化语义特征。（也就是辅助对特征进行分解的）因此生成器也就变为了$G(z,c)$。</p><p>然而，由于GANs非常的领会，生成器总会找到一个解，使得$P_G(x|z)=P_G(x)$，这样就会忽略潜在编码$c$对其的作用。为了解决这个问题，作者提出了$I(c;G(z,c))$用来表示潜在编码$c$和生成器结果$G(z,c)$之间的交互信息。为了$z$对生成器产生了足够大的影响，$I(c;G(z,c))$应该足够大。</p><p>$I(X;Y)$被定义为两个信息熵的插值，有公式：</p><script type="math/tex; mode=display">I(X;Y)=H(X)-H(X|Y)=H(Y)-H(Y|X) \tag{1}</script><p>对于任意给定的$x \sim P_G(x)$，我们希望$P_G(c|x)$有更小的信息熵，也就是$c$与$x$之间有更大的相关性。因此结合GAN的公式，我们的目标函数可以写为 </p><script type="math/tex; mode=display">\ min_G\  max_D\  V_I(D,G)=V(D,G)-\lambda I(c;G(z,c)) \tag{2}</script><p>然而在实际训练时，由于后验分布$P(c|x)$难以计算出来,我们很难将交互信息$I(c;G(z,c)) $直接最大化。因此作者提出利用另一个分布$Q(c|x)$来近似$P(c|x)$：</p><script type="math/tex; mode=display">\begin{align}I(c;G(z,c)) &= H(c)-H(c \vert G(z,c))\\&=\Bbb E_{x\sim G(z,c)}\left[\Bbb E_{c^{'}\sim P(c \vert x)}\left[\log P(c^{'} \vert x)\right]\right] +H(c) \\&=\Bbb E_{x\sim G(z,c)} \left[ \underbrace{D_{KL}(P(\cdot \vert x)\Vert Q(\cdot \vert x))}_{\ge 0}+ \Bbb E_{c^{'}\sim P(c \vert x)}\left[\log Q(c^{'} \vert x)\right] \right] +H(c) \\&\ge \Bbb E_{x\sim G(z,c)} \left[\Bbb E_{c^{'}\sim P(c \vert x)}\left[\log Q(c^{'} \vert x)\right] \right] +H(c)\tag{3}\end{align}</script><p>其中：</p><script type="math/tex; mode=display">\begin{align}D_{KL}(P(\cdot \vert x)\Vert Q(\cdot \vert x))&= \mathbb{E}_{c^{'}\sim P(c|x)}\left[\log\frac{P(c^{'}|x)}{Q(c^{'}|x)} \right] \\&=\mathbb{E}_{c^{'}\sim P(c|x)}\left[\log P(c^{'}|x) \right]-\mathbb{E}_{c^{'}\sim P(c|x)}\left[\log Q(c^{'}|x) \right]\tag{4}\end{align}</script><p>通过上面的处理方法，就绕过了需要后验分布$P(c|x)$的问题。事实上，$H(c)$作为潜在编码的熵也可以进行优化，但本文中将$H(c)$作为常量。通过观察式子我们发现，$c^{‘}$仍然需要从后验分布中进行采样($c^{‘}\sim P(c|x)$），因此作者通过证明$\mathbb{E}_{x\sim X, y\sim y|X} \left[f(x,y)\right]=\mathbb{E}_{x\sim X, y\sim y|X,x^{‘}\sim X|y} \left[f(x^{‘},y)\right]$，将公式再化为:</p><script type="math/tex; mode=display">\begin{align}L_1(G,Q) &=E_{x\sim G(z,c)}\left[\mathbb{E}_{c^{'}\sim P(c|x)}\left[\log Q(c^{'}|x)\right] \right]+H(c)\\&=E_{x\sim G(z,c),c\sim P(c)}\left[\log Q(c|x)\right]+H(c)\\&\le I(c;G(z,c)) \tag{5}\end{align}</script><p>因此，上述最大化$I(c;G(z,c)) $的过程可以用最大化$L_1(G,Q)$的过程来代替。它可以直接添加到GANs的目标函数中而不改变其训练过程。</p><p>由等式(3)可以发现，当$D_{KL}(P(\cdot \vert x)\Vert Q(\cdot \vert x)) \to 0$的时候，边界条件会变得更好。同时当$L_1(G,Q)$达到最大值时，说明$c$与$G(z,c)$之间的交互信息最多，达到其边界条件。</p><p>因此，<strong>InfoGAN</strong>的目标函数可以定义为</p><script type="math/tex; mode=display">\ min_G\  max_D\  V_{InfoGAN}(D,G,Q)=V(D,G)-\lambda L_1(G,Q) \tag{6}</script><blockquote><p>在训练过程中，一般D与Q有相同的结构，他们共享所以卷积层的参数，或者Q比D多一个全连接层来输出条件分布$Q(c|x)$。</p></blockquote><p>以上为<strong>InfoGAN</strong>的基本理论知识。InfoGAN的网络结构如下图所示</p><p><img src="InfoGAN.assets/InfoGAN.png" srcset="/img/loading.gif" alt="InfoGAN" style="zoom:67%;" /></p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>生成式对抗网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BicycleGAN论文</title>
    <link href="/2019/07/23/BicycleGAN/"/>
    <url>/2019/07/23/BicycleGAN/</url>
    
    <content type="html"><![CDATA[<p>最近看了关于 <strong>BicycleGAN</strong> 的一篇论文，在此将自己看论文的收获记录于此。因为阅读该篇论文是算本人的一个任务，所以看的比较详细，下面写的也非常详细，基本上是按照论文的逻辑写下来的。如果仅仅是想大致了解什么是<strong>BicycleGAN</strong>，可以看其他人的介绍，我的博客中仅看最后一部分即可，是我研究代码后得出的网络结构。</p><a id="more"></a><p>最近看过一篇论文<a href="https://arxiv.org/pdf/1711.11586.pdf" target="_blank" rel="noopener">Toward multimodal Image-to-Image translation</a>，讲述的主要是关于 <strong>BicycleGAN</strong> 的生成式对抗网络模型。在网上也看到过一些相关的博客，但讲得不算深入。因此在此将自己看论文的收获记录于此。</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>一般的生成式对抗网络，为单模态的。也就是给你一个真实的图片(ground truth)，网络的任务是生成与该图片非常接近的图片，不管是在颜色上，形状上还是其他方面。 而 <strong>BicycleGAN</strong> 的不同之处在于，该网络生成的图片不求与原图片完全相同，但求在生成的图像判断为真实图像的情况下，可以与原图像有风格上的差异。如果以环境图像为例的话可以参看下图</p><p><img src="BicycleGAN.assets/Figure1.png" srcset="/img/loading.gif" alt="Figure1" style="zoom:67%;" /></p><p>其中，真实的图像为一个夜景。而我们的目的是生成与该场景对应的白天的图像。我们要求白天的图像是多元的，但同时要求它看上去是真实的。</p><blockquote><p>我们可以自己先考虑一下，如何才能让最后的输出变得多元？那就是在对生成器输入的时候加入噪声。那么应该怎么加噪声，以及应该加什么样的噪声呢，可以继续往下看。</p></blockquote><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>首先从 <a href="https://arxiv.org/pdf/1611.07004v1.pdf" target="_blank" rel="noopener"><strong>pix2pix框架</strong> </a>谈起。<strong>pix2pix框架</strong> 已经证明可以为图像到图像的转换提供高质量的结果，但它只能输出单一的图像。并且即使在输入时添加随机噪声，仍得不到多元的输出结果。因此作者提出，在输出和潜在空间之间建立一种<a href="https://baike.baidu.com/item/%E5%8F%8C%E5%B0%84/942799?fr=aladdin" target="_blank" rel="noopener">双射</a>，使网络既能够执行潜在空间（和输入）映射到输出的任务，同时还学习从输出回到潜在空间的编码器。这样使得不同的随机噪声不会产生相同的输出。</p><p> 作者从以下两个无条件生成模型出发，对模型进行改进</p><ul><li><strong>cVAE-GAN (Conditional Variational Autoencoder GAN): </strong> 一个方法是先将真实图像(Groud truth) 利用编码器映射到潜在空间，得到一个条件噪声 $Q(z|B)$。然后将其和输入图像一起送入到生成器中进行训练，得到输出图像。为了确保  $Q(z|B)$  的随机性，我们利用<a href="https://www.cnblogs.com/nlpowen/p/3620470.html" target="_blank" rel="noopener">KL距离</a>来将其与正态分布进行比较，计算其损失。</li><li><strong>cLR-GAN (Conditional Latent Regressor GAN): </strong> 另一个方法先提供一个随机的潜在向量，将其与输入图像一起送入生成器，得到生成图像。然后利用一个编码器将生成图像恢复为初始的随机向量。这个生成的向量和一开始随机的潜在向量之间存在一个损失。</li><li><strong>BicycleGAN: </strong> 将以上两个模型结合得到我们的模型。（真的是直接框起来了……，结合起来后变成一个什么网络结构也没画出来。当时看的要吐血。但研究代码后，我终于弄清楚了，在后面给出。先给原论文中的图）<br><img src="BicycleGAN.assets/Figure2.png" srcset="/img/loading.gif" alt="Figure2" style="zoom:67%;" /></li></ul><h3 id="多模态图像到图像的转换"><a href="#多模态图像到图像的转换" class="headerlink" title="多模态图像到图像的转换"></a>多模态图像到图像的转换</h3><p>我们的目标是在两个数据域之间学习一个多模态的映射。考虑输入域 $\mathcal{A} \subset \mathbb{R}^{H \times W  \times 3}$ ，它被映射到输出域 $\mathcal{B} \subset \mathbb{R}^{H \times W  \times 3}$ 。在训练过程中，我们的数据集是来自这两个数域的成对的数据,  $\left\{ A \subset \mathcal{A}, B \subset\mathcal{B} \right\}$ 。事实上，对于输入 $A$ ，可能有很多实例 $B$ 与其对应，但我们的训练数据集仅包含这样的一对数据。而我们的模型，是为了在输入一个新的实例 $A$ 的情况下，可以生成一个 $\hat{\mathcal{B}}$ ,其中包含多个可能的 $\hat{B}$ ，分别对应着不同的 $p(B|A)$ 。</p><p>虽然条件生成式对抗网络$(CGANs$) 在图像-图像转换任务取得了成功，但对入输入图像$A$，它受限于仅生成单个（确定）的图像 $\hat{B}$。在前面我们提到，我们先学习一个低维的潜在空间$z\in\mathbb{R}^Z$,它包含了输出模式中一些非常模糊的方面，像$Figure1$中的云层，光线等等，这些在输入图像中并不能直接体现出来。因此我们便可以将一张夜景的图像映射为具有不同云层，不同光线的图像。然后我们再学习一个确定性的映射$G:(A,z)\to B$,为了实现随机抽样，我们希望从先验分布$p(z)$中抽取潜在向量$z$,在这个过程中，使用标准正态分布$\mathscr{N}(0,I)$。</p><h4 id="1-Baseline-pix2pix-noise-z-to-hat-B"><a href="#1-Baseline-pix2pix-noise-z-to-hat-B" class="headerlink" title="1.Baseline: pix2pix+noise($z\to\hat{B}$)"></a>1.Baseline: pix2pix+noise($z\to\hat{B}$)</h4><p>对抗性损失如下：</p><script type="math/tex; mode=display">\mathcal{L}_{GAN}(G,D)=\mathbb{E}_{A,B\sim p(A,B)}[log(D(A,B))]+\mathbb{E}_{A\sim p(A),z\sim p(z)}[log(1-D(G(A,z)))] \tag{1}</script><p>为了使得输出 $\hat{B}$ 更加契合原始图像$B$,同时增强模型的稳定性，在输出图像和原始图像之间定义$\mathcal{l_1}$损失。</p><script type="math/tex; mode=display">\mathcal{L_1^{image}}(G)=\mathbb{E_{A,B\sim p(A,B)}}||B-G(A,z)||_1 \tag{2}</script><p>总的损失函数为：</p><script type="math/tex; mode=display">G^*=arg \ min_G\  max_D\   \ {\mathcal L_{GAN}(G,D)+\lambda \mathcal{L_1^{image}}(G)} \tag{3}</script><p>然而这种方法并不合适，在 <strong>pix2pix</strong> 的原论文中作者也提到，生成器会忽略添加的噪声noise，因此最终将其在实验中删除。</p><h4 id="2-Conditional-Variational-Autoencoder-GAN-cVAE-GAN-hat-B-to-z-to-hat-B"><a href="#2-Conditional-Variational-Autoencoder-GAN-cVAE-GAN-hat-B-to-z-to-hat-B" class="headerlink" title="2.Conditional Variational Autoencoder GAN: cVAE-GAN($\hat{B}\to z\to\hat{B}$)"></a>2.Conditional Variational Autoencoder GAN: cVAE-GAN($\hat{B}\to z\to\hat{B}$)</h4><p>让低维向量<script type="math/tex">z</script>强制对生成多元化的输出图像产生作用的方法是利用编码器<script type="math/tex">E</script>得到 $Q(z|B)$ 。这样，生成器<script type="math/tex">G</script>就可以同时利用低维向量<script type="math/tex">z</script>和输入图像<script type="math/tex">A</script>来合成输出图像<script type="math/tex">\hat{B}</script>。此过程可以在Figure2(c)很好的展示出来。（相较于<strong>VAE-GAN</strong>，输入图像$A$为condition）</p><p>这种方法在无条件的变分自动编码器中取得了成功。将其应用到条件变分自动编码器时，我们可以假设$Q(z|B)$ 满足高斯分布$\mathscr{N}(0,I)$,因此$Q(z|B)\overset{\bigtriangleup}{= }E(B)$。为了反映这一点，公式$(1)$改为对$z\sim E(B)$进行采样，允许其进行发现传播。</p><script type="math/tex; mode=display">\mathcal{L}^{VAE}_{GAN}=\mathbb{E}_{A,B\sim p(A,B)}[log(D(A,B))]+\mathbb{E}_{A,B\sim p(A,B),z\sim E(B)}[log(1-(D(A,G(A,z))))]\tag{4}</script><p>我们对公式$(2)$中的$\mathcal{l_1}$损失进行变化，得到$\mathcal{L}_1^{VAE}(G)=\mathbb{E_{A,B\sim p(A,B),z\sim p(z)}}||B-G(A,z)||_1 $。此外，当$B$未知时，我们鼓励$E(B)$更加趋近于高斯分布。</p><script type="math/tex; mode=display">\mathcal{L}_{KL}(E)=\mathbb{E}_{B\sim p{B}}[\mathcal{D}_{KL}(E(B)|| \mathcal{N}(0,I)]  \tag{5}</script><p>因此我们有条件的<strong>VAE-GAN</strong>其模型可写为：</p><script type="math/tex; mode=display">G^*,E^*=arg \ min_{G,E}\  max_D\   \ \mathcal {L}^{VAE}_{GAN}(G,D,E)+\lambda \mathcal{L}_1^{VAE}(G) +\lambda_{KL} \mathcal{L}_{KL}(E)\tag{6}</script><p>作为基准，文章还考虑该方法的确定性版本。即，丢弃$KL$距离并编码$z = E(B)$。 该方法称为cAE-GAN。在实验中比较显示， cAE-GAN无法保证潜在空间$z$的分布，使得$z$的测试时间采样变得困难。</p><h4 id="3-Conditional-Latent-Regressor-GAN-cLR-GAN-z-to-hat-B-to-hat-z"><a href="#3-Conditional-Latent-Regressor-GAN-cLR-GAN-z-to-hat-B-to-hat-z" class="headerlink" title="3.Conditional Latent Regressor GAN: cLR-GAN($z\to \hat{B} \to \hat{z}$)"></a>3.Conditional Latent Regressor GAN: cLR-GAN($z\to \hat{B} \to \hat{z}$)</h4><p>文章还探索了另一种强制生成器利用低维向量$z$的方法。像在$Figure2(c)$中展示的那样。我们从随机向量$z$作为输入开始，并且尝试利用公式$\hat{z}=E(G(A,z))$在最后恢复它。值得注意的是这里生成的$\hat{z}$为点估计，而上部分向量$\hat{z}$预测为高斯分布。</p><script type="math/tex; mode=display">\mathcal{L_1^{latent}}(G,E)=\mathbb{E}_{A\sim p(A),z\sim p(z)}||z-E(G(A,z))||_1 \tag{7}</script><p>和公式$(1)$一样，我们同样有$\mathcal{L}_{GAN}$损失使网络生成更加真实的结果。整个网络的损失可以写为：</p><script type="math/tex; mode=display">G^*,E^*=arg \ min_{G,E}\  max_D\   \ {\mathcal L_{GAN}(G,D )+\lambda_{latent} \mathcal{L_1^{latent}}(G,E)} \tag{8}</script><p>在该模型中，并没有在真实图像$B$和输出图像$\hat{B}$之间计算其$\mathcal{l}_1$损失。因为我们不要求这两者之间完全一样，但要求$\hat{B}$必须看上去是真实的。（基于这个原因，为什么上个模型需要$\hat{l}_1$损失我也搞不清楚……）</p><h4 id="4-OurHybridModel-BicycleGAN"><a href="#4-OurHybridModel-BicycleGAN" class="headerlink" title="4.OurHybridModel: BicycleGAN"></a>4.OurHybridModel: BicycleGAN</h4><p>将<strong>cVAE-GAN</strong>和<strong>cLR-GAN</strong>组合为混合模型，得到我们的模型<strong>BicycleGAN</strong>。对于<strong>cVAE-GAN</strong>，网络是从实际数据中学习的，但随机向量$z$在测试时可能无法产生逼真的图像—$KL$损失可能无法很好地优化。 更重要的是，判别器$D$在训练期间得不到前面采样的信息（因为$Q(z|B)$是先验分布，而不是随机抽样得来的）。在<strong>cLR-GAN</strong>中，随机向量$z$很容易从简单的分布中采样，但是生成器在训练过程中没有得到真实图像的输入对其的优化（可对比cVAE-GAN来看）。将这两个模型结合起来，可以同时具备这两个循环（$\hat{B}\to z\to\hat{B}$， $z\to \hat{B} \to \hat{z}$）的优势。总的损失为：</p><script type="math/tex; mode=display">G^*,E^*=arg \ min_{G,E}\  max_D\  \  \mathcal{ L}^{VAE}_{GAN}(G,D,E)+\lambda\mathcal{L}_1^{VAE}(G) +\mathcal L_{GAN}(G,D )+\lambda_{latent} \mathcal{L}_1^{latent}(G,E) +\lambda_{KL} \mathcal{L}_{KL}(E)\tag{9}</script><p>论文的内容到此就结束了。接下来主要是我研究代码后学到的一些内容。因为论文中具体的网络结构并不清楚，在看完代码后才理清了思路。并且利用TensorFlow画出来graph来。(GitHub上论文的<a href="https://github.com/gitlimlab/BicycleGAN-Tensorflow" target="_blank" rel="noopener">TensorFlow版本代码</a>，原作为<a href="https://github.com/junyanz/BicycleGAN" target="_blank" rel="noopener">PyTorch版本</a>)</p><p>我自己看PyTorch版本代码画出的结构图（尽力了，呼……）<br><img src="BicycleGAN.assets/net.png" srcset="/img/loading.gif" alt="net" style="zoom:67%;" /></p><p>利用Tensorboard画的graph</p><p><img src="BicycleGAN.assets/graph.png" srcset="/img/loading.gif" alt="graph" style="zoom:67%;" /></p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>生成式对抗网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>My first blog!!!</title>
    <link href="/2019/07/23/my%20first%20blog/"/>
    <url>/2019/07/23/my%20first%20blog/</url>
    
    <content type="html"><![CDATA[<p> 心心念念的博客终于搭建完成了！<br> 现在坐在浙大西溪校区的宿舍中，宿舍中间是一套长长的桌子，我坐在桌子的最边上，右边紧靠着窗户。因为外面是35°C的高温，所以窗户上半拉着窗帘。开着空调，很舒服(#^.^#)<br> 下一篇博客就以最近看的论文为内容了，好好珍惜自己的博客吧！</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
